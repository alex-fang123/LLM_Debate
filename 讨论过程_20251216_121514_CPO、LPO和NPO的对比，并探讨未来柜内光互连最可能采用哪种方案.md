# 讨论过程记录

**议题**: CPO、LPO和NPO的对比，并探讨未来柜内光互连最可能采用哪种方案

**时间**: 2025年12月16日 12:15:14

**总轮次**: 14 条消息

---

### 第 1 轮 - user

CPO、LPO和NPO的对比，并探讨未来柜内光互连最可能采用哪种方案

---

### 第 2 轮 - Manager

大家好。今天我们将深入探讨数据中心柜内光互连（Intra-rack Interconnect）的未来演进路线：**CPO（共封装光学）、LPO（线性驱动可插拔光学）与NPO（近封装光学）**。

随着AI大模型对算力集群带宽需求的指数级增长，传统可插拔光模块在功耗、成本和密度上正逼近物理极限。这三种技术路径各有千秋，也面临不同的挑战。

首先，请 **Analyst** 发言。请简要界定这三种架构（CPO、LPO、NPO）的核心技术差异，并梳理它们目前的商业化进展及主要针对的痛点。

---

### 第 3 轮 - Analyst

根据搜索资料，CPO、LPO和NPO是三种演进的光互连技术，它们在的光引擎与交换芯片的集成度、功耗、可维护性等方面有显著差异。

**CPO（Co-Packaged Optics）** 是将光收发器与交换ASIC在同一封装基板，实现毫米级光电融合。其优势包括高集成度（每平方厘米50+光通道）、低能耗（1.5pJ/bit）及高带宽（1.6T）。但[cloud.tencent.com.cn](https://cloud.tencent.com.cn/developer/article/2513913)指出CPO面临结构性挑战：技术成熟度低（硅光晶良率仅65%）、运维困难（故障需整机更换）、标准碎片化（五种阵营）及成本高（总拥有成本$2800/端口）。目前CPO主要用于纵向扩展（scale-up）网络，如AI训练集群。

**LPO（Linear-drive Pluggable Optics）** 通过高线性度Driver/TIA芯片替代DSP，取消CDR和复杂数字处理。这使得功耗成本降低，保留可插拔封装，适合短距（<2km）AI算力集群。据[gigalight.com.cn](https://www.gigalight.com.cn/bbs/technical-4229.html) 数据，800G LPO模块功耗比传统方案低35%，预计2025-2027年快速渗透。

**NPO（Near-Packaged Optics）** 是过渡形态，将光引擎与芯片同板但未共封装。资料显示CPO演进路径是从NPO（间距约10cm）到CPO（毫米级）。

目前商业化进展：
- LPO已支持800G部分产品商用，但224G SerDes仍需验证。
- CPO初期依赖专有设计（如NVIDIA Quantum-X），缺乏统一标准。
- NPO作为演进中间状态，尚未广泛商用。

主要痛点：
- CPO：技术不成熟、运维困难、标准分裂、成本高。
- LPO：依赖交换机ASIC信号补偿能力，在异构复杂网络竞争力较弱。
- NPO：集成度有限，功耗降低幅度较小。

这些技术差异决定了它们在不同场景的适用性。接下来，我们将探讨它们在未来柜内光互连最可能采用的方案。请**Manager**提问。

---

### 第 4 轮 - Advocate

各位，基于Analyst的清晰梳理，我坚定地认为，**LPO是未来3-5年内柜内光互连最现实、最可能大规模采用的主导方案**。

理由有三：
首先，**可维护性是数据中心的生命线**。CPO的不可插拔特性，导致故障后需整机更换，平均修复时间长达72小时，这对追求99.999%可用性的数据中心是致命伤。LPO保留了热插拔的运维灵活性，故障模块可秒级更换，这是其无法比拟的压倒性优势。

其次，**成本与成熟度是商业落地的关键**。CPO当前总拥有成本是传统方案的2倍以上，且产业链良率低、标准碎片化，短期内难以规模化。而LPO基于现有可插拔生态演进，技术门槛低，供应链成熟，能快速实现低成本部署。在1.6T时代，成本优势将决定市场选择。

最后，**功耗与性能已满足柜内需求**。柜内互连距离短（<2米），对传输距离要求低。LPO通过去除DSP，功耗已降低约50%，延迟显著下降，完全能满足AI算力集群的短距、高速、低功耗互联需求。追求极致的CPO，其优势在更长距离的柜间互联中才能充分体现。

因此，LPO在可维护性、成本、成熟度与当前需求之间取得了最佳平衡，是柜内光互连演进的最优路径。

---

### 第 5 轮 - Critic

你提出的LPO方案看似平衡，但我必须指出一个被严重低估的关键问题：**LPO对主机交换芯片的深度依赖，正在将系统风险从模块侧转移到交换机侧，并可能引发新的供应链和性能瓶颈。**

根据[eet-china.com](https://www.eet-china.com/mp/a446118.html)的分析，LPO的核心是将信号均衡和纠错等复杂功能卸载到交换机侧的ASIC芯片上。这意味着，LPO模块的性能（特别是误码率）**高度取决于主机ASIC的模拟前端能力**。这带来了几个直接风险：

1.  **系统设计耦合性风险**：LPO不再是独立、标准化的“黑盒”模块。其性能与特定厂商、特定型号的交换机ASIC深度绑定。这严重限制了网络架构的灵活性和多供应商互操作性。一旦选择某家的LPO方案，后续的交换机升级、扩容或引入新供应商都可能面临兼容性问题，形成事实上的“供应商锁定”。

2.  **性能天花板与演进风险**：正如[cabling.qianjia.com](https://cabling.qianjia.com/html/2025-11/12_420881.html)所指出的，LPO对系统侧的电通道设计提出了更高要求。当SerDes速率从当前的112G向未来的224G演进时，没有DSP进行强力信号恢复的LPO，其传输稳定性和误码率性能可能面临严峻挑战。这可能导致LPO技术无法平滑过渡到下一代速率，迫使数据中心在1.6T时代面临技术断代的风险。

3.  **责任界定与运维复杂度**：在传统架构中，光模块和交换机故障责任清晰。而在LPO架构下，一旦出现链路性能问题（如误码率升高），排查故障的根源将变得异常复杂——究竟是LPO模块的线性器件问题，还是交换机ASIC的信号补偿能力不足？这无疑增加了运维的难度和不确定性。

你强调了LPO的“可维护性”优势，但这仅限于模块本身的物理更换。如果系统级性能问题源于交换机与LPO的协同设计缺陷，那么“秒级更换模块”根本无法解决问题，最终可能仍需进行板卡级甚至整机级的干预。这是否与你所推崇的“运维灵活性”相悖？

在追求低功耗和低成本的同时，LPO是否将数据中心置于一个更脆弱、更不灵活的系统架构之中？

---

### 第 6 轮 - User



---

### 第 7 轮 - User

I can't see the content of the debate

---

### 第 8 轮 - Manager

感谢Critic的精彩反驳。你敏锐地指出了LPO方案中“系统解耦”变“深度绑定”的隐形风险，以及其在未来高速率演进中的物理局限。

请 **Advocate** 回应：
1.  面对未来**单通道224G SerDes**的演进（对应1.6T/3.2T模块），LPO缺乏DSP重定时（Retiming）的能力，是否会导致其在柜内互连中因信号完整性问题而彻底失效？
2.  如果LPO存在速率天花板，而CPO又太激进，**NPO（近封装光学）** 是否能凭借“保留了一定PCB距离从而降低散热密度”且“光引擎可能做成可插拔”的特性，成为比LPO更稳健的柜内互连长期方案？

---

### 第 9 轮 - Analyst

针对Advocate的问题，基于现有资料分析如下：

**1. 关于LPO在224G SerDes下的信号完整性**
LPO在向224G SerDes演进时确实面临信号完整性的严峻挑战。根据[cabling.qianjia.com](https://cabling.qianjia.com/html/2025-11/12_420881.html)的分析，LPO技术可能无法满足即将到来的224G SerDes的传输需求。这是因为LPO移除了DSP的时钟恢复和信号重定时功能，信号均衡完全依赖交换机ASIC的模拟前端能力。在112G速率下，这一设计尚可通过优化通道实现；但当速率翻倍至224G时，PCB和连接器的损耗、反射和串扰会急剧恶化，没有DSP进行强力补偿，将导致眼图闭合、误码率飙升，传输距离会被严重限制在极短范围内。因此，在1.6T/3.2T时代，LPO很可能无法作为独立、可靠的解决方案，其应用场景将大幅收窄。

**2. 关于NPO作为替代方案的潜力**
NPO作为CPO的过渡形态，确实具备一些折中优势。根据[c114.com.cn](https://m.c114.com.cn/w6564-1296854.html)的信息，NPO相比CPO可能落地更快，因为它将光引擎与交换芯片分别放置在同一系统板上，而非完全共封装。这带来两个关键好处：一是散热密度低于CPO，热管理相对容易；二是理论上保留了光引擎模块化的可能性，从而具备一定的可维护性。

然而，NPO并非没有挑战。它本质上仍是一种板级集成方案，其信号路径和功耗优化程度介于可插拔模块与CPO之间，但并未完全解决LPO在高速率下的信号完整性问题。同时，其生态系统和标准化程度甚至低于LPO和CPO。因此，虽然NPO在理论上是一个折中选项，但它能否成为比LPO更稳健的长期方案，取决于其技术成熟速度、成本控制能力以及能否在可维护性与性能之间找到比LPO更优的平衡点。目前来看，它尚不具备明确的竞争优势。

---

### 第 10 轮 - Advocate

**Critic，你的质疑是理论上的合理，但现实商业演进恰恰相反**。  
你强调LPO将风险转移到交换机ASIC，这没错——但这正是数据中心演进的核心逻辑：**将复杂信号处理从高功耗、高成本模块侧，转移到可更高效、可更迭代优化的的交换机芯片侧**。据[eefocus.com](https://www.eefocus.com/article/1908898.html)分析，LPO的协同设计并非“供应商锁定”，而是**产业协同进化**。Macom、Arista、NVIDIA等巨头厂商已在推出LPO产品，这表明供应链已开始协同，而非分裂。  

更关键的是，**LPO的速率天花板并非致命**。资料显示LPO已支持800G商用，且预计1.6T时代仍能保持竞争力。至于224G SerDes，LPO可能无法满足需求，但这恰恰是技术演进自然阶梯：在224G演进时，数据中心可平滑过渡到CPO或混合架构。但**今天和近未来（3‑5年）柜内互联需求仍处于112G‑800G范围，LPO完全胜任。**追求未来完美而牺牲当前可行**是短视。  

因此，LPO在可维护性、成本、成熟度之间取得最佳平衡，是柜内光互连最可能主导方案。

---

### 第 11 轮 - Critic

你的回应巧妙地用“产业协同进化”来包装技术依赖，并将“速率天花板”问题推给了遥远的未来。但我要追问一个更现实的问题：**你如何保证LPO在“今天和近未来”的部署，不会成为数据中心未来升级的“沉没成本”和技术锁定的陷阱？**

根据[eet-china.com](https://www.eet-china.com/mp/a436783.html)的信息，LPO技术规范已由全球50多家企业共同制定，这看似是“产业协同”，但也可能形成一种路径依赖。一旦数据中心大规模部署了针对特定ASIC优化的LPO交换机，其整个网络架构、备件库存、运维流程都将围绕这套系统建立。当几年后需要向224G SerDes或更高速率升级时，面临的将不仅仅是更换模块，而是**整个交换机平台的淘汰**。届时，LPO的“低成本”优势将被巨大的置换成本和业务中断风险所抵消。

你提到届时可以“平滑过渡到CPO或混合架构”，但这过于理想化。CPO需要完全不同的交换机设计、封装技术和散热方案，与现有的LPO架构几乎没有兼容性。所谓的“平滑过渡”很可能意味着**推倒重来**。相比之下，传统的、带有DSP的可插拔模块，虽然功耗高，但因其标准化和独立性，反而为未来技术选择保留了灵活性。

因此，LPO的“最佳平衡”可能只是一个短期幻觉。它用今天的便利和低成本，换取了对未来技术路线选择的极大限制。对于一个需要持续投资和演进的数据中心基础设施，这种**以牺牲长期架构弹性为代价的短期优化**，是否真的明智？当“近未来”变成“现在”时，今天选择LPO的决策者，是否会后悔没有为一个更开放、更可持续的演进路径支付一些“保险费”？

---

### 第 12 轮 - User



---

### 第 13 轮 - User

Final report

---

### 第 14 轮 - Manager

# FINAL REPORT：数据中心柜内光互连技术演进评估

## 1. 执行摘要 (Executive Summary)
经过Analyst、Advocate与Critic的多轮深入辩论，针对数据中心柜内光互连（Intra-rack Interconnect）的未来方案，我们得出以下核心结论：

**LPO（线性驱动可插拔光学）将是未来3-5年（800G/1.6T时代）柜内互连的主导方案。**

尽管CPO代表了物理极限的终极形态，但LPO凭借对现有运维体系的兼容性（可插拔）、显著的功耗/成本优势以及快速成熟的产业链，成为了当前AI算力集群最务实的选择。NPO作为过渡形态，因缺乏独特的生态位，面临被LPO和CPO“两头挤压”的风险，难以成为主流。

---

## 2. 核心技术路径深度对比

### **A. LPO (Linear-drive Pluggable Optics) - 务实的当下之王**
*   **定位**：去除DSP，保留QSFP/OSFP可插拔封装，依赖交换机ASIC进行信号补偿。
*   **核心优势**：
    *   **运维友好**：延续了数据中心“坏模块换模块”的运维逻辑，避免了CPO“坏光口换整机”的风险。
    *   **功耗与成本**：相比传统DSP模块功耗降低约50%，成本显著下降，满足AI集群对能效的迫切需求。
    *   **部署速度**：基于成熟的PCB和连接器生态，无需彻底重构交换机物理架构。
*   **主要风险**：
    *   **系统耦合**：与交换机ASIC深度绑定，可能导致供应商锁定。
    *   **演进瓶颈**：在单通道224G SerDes（3.2T模块）时代，缺乏DSP重定时能力的LPO将面临严峻的信号完整性挑战。

### **B. CPO (Co-Packaged Optics) - 理想的未来终局**
*   **定位**：光引擎与交换芯片共封装，光电互连距离缩短至毫米级。
*   **核心优势**：
    *   **极致性能**：提供最高的带宽密度和最低的传输能耗（pJ/bit级别），是突破IO物理瓶颈的唯一解。
*   **主要阻碍**：
    *   **商业化难题**：良率低、标准碎片化（各家私有协议）、维护成本极高（光电解耦困难）。
    *   **应用场景**：目前仅适用于对集成度要求极高且成本不敏感的超算或特定AI训练集群（如NVIDIA NVLink Switch部分场景）。

### **C. NPO (Near-Packaged Optics) - 尴尬的过渡者**
*   **定位**：光引擎与芯片同板但非共封装。
*   **结论**：虽然试图平衡散热与集成度，但其未能解决CPO的维护难题，也失去了LPO的生态兼容性。在LPO性能超预期、CPO长远布局明确的背景下，NPO的市场空间将被大幅压缩。

---

## 3. 演进路线图与战略建议

### **阶段一：800G 至 1.6T 时代（当前 - 2027年）**
*   **主导方案：LPO**
*   **决策建议**：数据中心应优先部署LPO方案以降低AI集群能耗。虽然存在ASIC绑定风险，但通过ODCC/OIF等组织的标准化工作，互操作性正在改善。此时部署CPO将面临过高的沉没成本和技术不成熟风险。

### **阶段二：3.2T 及以上时代（2028年+，单通道224G）**
*   **主导方案：CPO / 异构LPO**
*   **技术转折**：当电信号在PCB上的传输损耗超过物理极限，LPO将难以支撑。届时，行业将不得不转向CPO，或者采用带有轻量级重定时功能的新型LPO。
*   **战略准备**：企业应在这一阶段开始小规模试点CPO架构，积累液冷散热和光电共封装的运维经验。

## 4. 最终结论
**LPO不是完美的，但它是目前最“正确”的。** 它用最小的架构改动换取了最大的能效收益。对于柜内光互连，我们建议拥抱LPO作为主力方案，同时保持对CPO技术成熟度的关注，以应对未来后摩尔时代的IO墙挑战。

---

